---
title: "RBighornVisitationAnalysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is my basic analysis of bighorn visitation to water, Summer 2019. First, I combined all of my observations into one dataframe. Due to some technical difficulties with the database at the CDFW office, I included observations from both a version of the database from 7/3 and 7/22 since I thought some had gotten deleted from the 7/22. I then removed fully duplicated rows in order to remove data that were in both the 7/3 and 7/22 database. The dataframe had 2108 observations before eliminating duplicated rows, and 2062 observations after the removal of duplicated rows. This makes sense as the approximate number of observations that I had input into the database by 7/3. Before coding further, I went through the SBrs and Marb data and visually checked that there were observations for every date that were supposedly covered. The only discrepancy that I found was that there were no observations in the Marbles on 6/25 after 14:49 pm. I went into the photo data and confirmed that this was indeed the case. Perhaps it was a really cool afternoon?

I then formatted the data where major things needed to be fixed. I changed the cells of  KI_DG_FirstPhotoTime2, KI_DG_FirstPhotoTime3, KI_DG_FirstPhotoTime4, KI_DG_LastPhotoTime2, KI_DG_LastPhotoTime3, and KI_DG_LastPhotoTime4 that were '0' or blank to NAs. I also changed the cells of KI_DG_SheepDrank2, KI_DG_SheepDrank3, and KI_DG_SheepDrank4 that were blank to NAs. 




```{r}
AshleyDataall <- read.csv("AshleyDatabasequeryall121419.csv", header = TRUE, sep = ",")
twodbobs <- read.csv("ObservationsBeginningoftheSummer2databases121419.csv", header = TRUE, sep = ",")
firstpartdgobs <- read.csv("NopaCMPRMarbfirstpartofsummerDanielleObservations.csv", header = TRUE, sep = ",")
threedf <- rbind(AshleyDataall, twodbobs, firstpartdgobs)
library(tidyverse)
nodups <- distinct(threedf)
table(duplicated(nodups))
table(duplicated(nodups$DateObsTimeIDwaterspecific))
# THERE ARE NO DUPLICATES OF THE ROWS OVERALL, BUT THERE ARE 204 DUPLICATES OF THE NODUPS$DateObsTimeODwaterspecific. WHY?!!!!!!! B/C some of the observations have the capture data and some don't. I SHOULD BE ABLE TO FIX THIS AFTER INPUTTING THE CORRECT WEIGHTS, BODY LENGTHS, AND CHEST GIRTHS THAT ARE MISSING.
View(duplicated(nodups$DateObsTimeIDwaterspecific))

as.character(nodups$KI_DG_FirstPhotoTime2, nodups$KI_DG_LastPhotoTime2, nodups$KI_DG_FirstPhotoTime3, nodups$KI_DG_LastPhotoTime3, nodups$KI_DG_FirstPhotoTime4, nodups$KI_DG_LastPhotoTime4)
nodups$KI_DG_FirstPhotoTime2[nodups$KI_DG_FirstPhotoTime2 == "0"] <- NA
nodups$KI_DG_FirstPhotoTime2[nodups$KI_DG_FirstPhotoTime2 == ""] <- NA
nodups$KI_DG_LastPhotoTime2[nodups$KI_DG_LastPhotoTime2 == "0"] <- NA
nodups$KI_DG_LastPhotoTime2[nodups$KI_DG_LastPhotoTime2 == ""] <- NA
nodups$KI_DG_FirstPhotoTime3[nodups$KI_DG_FirstPhotoTime3 == "0"] <- NA
nodups$KI_DG_FirstPhotoTime3[nodups$KI_DG_FirstPhotoTime3 == ""] <- NA
nodups$KI_DG_LastPhotoTime3[nodups$KI_DG_LastPhotoTime3 == "0"] <- NA
nodups$KI_DG_LastPhotoTime3[nodups$KI_DG_LastPhotoTime3 == ""] <- NA
nodups$KI_DG_FirstPhotoTime4[nodups$KI_DG_FirstPhotoTime4 == "0"] <- NA
nodups$KI_DG_FirstPhotoTime4[nodups$KI_DG_FirstPhotoTime4 == ""] <- NA
nodups$KI_DG_LastPhotoTime4[nodups$KI_DG_LastPhotoTime4 == "0"] <- NA
nodups$KI_DG_LastPhotoTime4[nodups$KI_DG_LastPhotoTime4 == ""] <- NA


as.character(nodups$KI_DG_SheepDrank2, nodups$KI_DG_SheepDrank3, nodups$KI_DG_SheepDrank4)
nodups$KI_DG_SheepDrank2[nodups$KI_DG_SheepDrank2 == ""] <- NA
nodups$KI_DG_SheepDrank3[nodups$KI_DG_SheepDrank3 == ""] <- NA
nodups$KI_DG_SheepDrank4[nodups$KI_DG_SheepDrank4 == ""] <- NA

as.character(nodups$GO_DG_SpecificSource)
nodups$GO_DG_SpecificSource[nodups$GO_DG_SpecificSource == ""] <- NA
as.factor(nodups$GO_DG_SpecificSource)

```
A List of everything that needs to be fixed:
- input the GPS location as per the GO_WaterSource. Make sure to input the type of GPS data (UTM, latlong) that is relevant to the GPS Data cleaning stuff. 
- change the data type of every column to the correct type
- at some point, subset the KI_Known_ID for the sheep I am interested in for the GPS analysis
- input the missing KI_Sex cells - DONE
- input the missing KI_DG_FirstPhotoTime and KI_DG_LastPhotoTime times, and the missing Ki_DG_SheepDrank (there's a ton of these - Ashley???)- Don't need to - these are the other sheep
- check that all of the comp numbers are numbers and are appropriate. And that there are no blanks and NAs.
- If possible, fill in the weights, body lengths, and chest girths that are missing.- DONE
-KI_DatObsT_ID has 1858 levels, but there are 2062 entries - DONE
- GO_DatObsTime and KI_DatObsT_ID are wrong for some entries. Need to remake in order to use!- DONE
- put in age for some of them- DONE
- also missing chest girth, body length, weight for some (BHS_1492)- DONE
- Fix ages

- subset to the correct mtn ranges
- figure out the replication for the ones that have multiple visits in 1 observation
- sheep drank has 53 blanks and 1 problematic Y
- Cat 2 has a NA that probs should be 0?



In an attempt to figure out why there was still duplicated rows, I made a column with everything needed to make each observation individually identifiable. I discovered that some rows did not have the capture data needed, and that this was what was making the duplicated rows not seen as duplicated. I then worked to input the missing information - weight, body length, and chest girth. I subset by the distinct rows and this equaled the previous number of individually identifiable observations. 


```{r}
as.character(nodups$GO_Date, nodups$KI_Known_ID, nodups$GO_Time_HHMM, nodups$GO_WaterSource, nodups$GO_DG_SpecificSource)
nodups$DateObsTimeIDwaterspecific <- paste(nodups$GO_Date, nodups$KI_Known_ID, nodups$GO_Time_HHMM, nodups$GO_WaterSource, nodups$GO_DG_SpecificSource, sep = "")
as.character(nodups$KI_Sex)
as.character(nodups$KI_Known_ID)
table(nodups$KI_Sex)
nodups$KI_Sex[nodups$KI_Known_ID == "BHS_1489" | nodups$KI_Known_ID == "BHS_1596" | nodups$KI_Known_ID == "BHS_1361" | nodups$KI_Known_ID == "BHS_1357" | nodups$KI_Known_ID == "BHS_1367" | nodups$KI_Known_ID == "BHS_1362" | nodups$KI_Known_ID == "BHS_1584" | nodups$KI_Known_ID == "BHS_1585" | nodups$KI_Known_ID == "BHS_1583" | nodups$KI_Known_ID == "BHS_1582" | nodups$KI_Known_ID == "BHS_1588" | nodups$KI_Known_ID == "BHS_1365" | nodups$KI_Known_ID == "BHS_1574" | nodups$KI_Known_ID == "BHS_1366" | nodups$KI_Known_ID == "BHS_1594" | nodups$KI_Known_ID == "BHS_1577" | nodups$KI_Known_ID == "BHS_1581" | nodups$KI_Known_ID == "BHS_1576" | nodups$KI_Known_ID == "BHS_1416" | nodups$KI_Known_ID == "BHS_1587" | nodups$KI_Known_ID == "BHS_1575" | nodups$KI_Known_ID == "BHS_1592" | nodups$KI_Known_ID == "BHS_1589" | nodups$KI_Known_ID == "BHS_1421" | nodups$KI_Known_ID == "BHS_1740" | nodups$KI_Known_ID == "BHS_1738" | nodups$KI_Known_ID == "BHS_1736" | nodups$KI_Known_ID == "BHS_1734" | nodups$KI_Known_ID == "BHS_1733" | nodups$KI_Known_ID == "BHS_1741"] <- "F"

nodups$KI_Sex[nodups$KI_Known_ID == "BHS_1494" | nodups$KI_Known_ID == "BHS_1684" | nodups$KI_Known_ID == "BHS_1683" | nodups$KI_Known_ID == "BHS_1682" | nodups$KI_Known_ID == "BHS_1493" | nodups$KI_Known_ID == "BHS_1591" | nodups$KI_Known_ID == "BHS_1590" | nodups$KI_Known_ID == "BHS_1420" | nodups$KI_Known_ID == "1728" | nodups$KI_Known_ID == "BHS_1739"] <- "M"

# table(nodups$KI_Known_ID) - going through the individual sheep to check and make sure their weight, body length, and chest girth are filled out correctly.
# table(nodups$KI_Known_ID[!is.na()])

# LIST OF SHEEP THAT HAVE MEASUREMENTS (* sheep that had different measurements?, ^ sheep that I am checking measurements with CDFW): BHS_1420^, BHS_1428*, BHS_1490*, BHS_1492^, 1493*, 1494*, 1563, 1565, 1574, 1575, 1576, 1577, 1581, 1582, 1583, 1587, 1592, 1594, 1682, 1683, 1684, 1689, 1713, 1730, 1731, 1733, 1734, 1736, 1738, 1739 
# nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == ""]
#### NEED TO FIX ID THAT HAS "BHs_1596" to "BHS_1596"!!!!!!!!

as.character(nodups$KI_Known_ID)
nodups$KI_Known_ID[nodups$KI_Known_ID == "BHs_1596"] <- "BHS_1596"
as.factor(nodups$KI_Known_ID)
# now comes back at BHs_1596 = 0, BHS_1596=78 - did this truly fix the problem?

# Four of the bighorn have two different numbers at their measurements. I am going to set them to the lower number b/c the higher number is probably the untarred number.
#BHS_1428 - body length comes back at both 151.3 and 149.0. I am going to set it to 149.0 b/c that is what in the 7/22 database and because the higher number is probably the untarred number.

# There are measurements that are not in the 7/22 database that are in my datasheet. I need to add the measurements for the sheep that this is true so as to make there be no duplicated rows. 

# BODY LENGTHS:
as.character(nodups$CP_BdyLgth_cm)
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1420"] <- "155.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1428"] <- "149.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1490"] <- "158.2"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1492"] <- "152.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1493"] <- "162.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1494"] <- "145.1"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1563"] <- "165.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1565"] <- "136.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1574"] <- "146.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1575"] <- "143.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1576"] <- "141.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1577"] <- "141.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1581"] <- "139.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1582"] <- "138.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1583"] <- "142.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1587"] <- "139.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1592"] <- "137.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1594"] <- "125.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1682"] <- "140.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1683"] <- "144.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1684"] <- "149.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1689"] <- "155.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1713"] <- "140.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1730"] <- "152.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1731"] <- "161.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1733"] <- "153.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1734"] <- "149.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1736"] <- "118.0"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1738"] <- "130.5"
nodups$CP_BdyLgth_cm[nodups$KI_Known_ID == "BHS_1739"] <- "145.0"
as.numeric(nodups$CP_BdyLgth_cm)


#CHEST GIRTHS
as.character(nodups$CP_ChstGth_cm)
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1420"] <- "111.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1428"] <- "100.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1490"] <- "101.8"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1492"] <- "105.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1493"] <- "111.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1494"] <- "104.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1563"] <- "107.2"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1565"] <- "99.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1574"] <- "95.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1575"] <- "99.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1576"] <- "97.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1577"] <- "99.1"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1581"] <- "101.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1582"] <- "92.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1583"] <- "93.2"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1587"] <- "97.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1592"] <- "103.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1594"] <- "98.9"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1682"] <- "98.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1683"] <- "95.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1684"] <- "102.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1689"] <- "108.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1713"] <- "97.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1730"] <- "101.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1731"] <- "115.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1733"] <- "109.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1734"] <- "96.0"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1736"] <- "82.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1738"] <- "84.5"
nodups$CP_ChstGth_cm[nodups$KI_Known_ID == "BHS_1739"] <- "96.0"
as.numeric(nodups$CP_ChstGth_cm)

#WEIGHT - this is unadjusted, raw weight (no tar)b/c the vast majority of the entries do not have a tar weight or a net weight.
as.character(nodups$CP_Weight..kg.)
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1420"] <- "96.5"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1428"] <- "63.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1490"] <- "82.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1492"] <- "88.4"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1493"] <- "87.4"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1494"] <- "64.6"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1563"] <- "89.8"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1565"] <- "61.3"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1574"] <- "63.6"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1575"] <- "67.1"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1576"] <- "58.5"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1577"] <- "61.3"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1581"] <- "68.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1582"] <- "59.2"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1583"] <- "63.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1587"] <- "65.5"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1592"] <- "60.5"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1594"] <- "56.5"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1682"] <- "61.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1683"] <- "64.6"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1684"] <- "76.3"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1689"] <- "85.2"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1713"] <- "59.6"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1730"] <- "69.0"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1731"] <- "100.04"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1733"] <- "77.3"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1734"] <- "58.6"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1736"] <- "47.1"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1738"] <- "44.2"
nodups$CP_Weight..kg.[nodups$KI_Known_ID == "BHS_1739"] <- "71.8"
as.numeric(nodups$CP_Weight..kg.)

# AGE AT TIME OF CAPTURE:
as.character(nodups$CP_AgeYears)
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1420"] <- "6"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1428"] <- "3"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1490"] <- "7"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1492"] <- "8"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1493"] <- "7"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1494"] <- "4"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1563"] <- "4"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1565"] <- "4"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1574"] <- "10"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1575"] <- "5"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1576"] <- "8"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1577"] <- "5"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1581"] <- "5"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1582"] <- "5"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1583"] <- "6"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1587"] <- "6"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1592"] <- "5"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1594"] <- "7"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1682"] <- "3"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1683"] <- "3"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1684"] <- "12"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1689"] <- "9"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1713"] <- "6"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1730"] <- "4"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1731"] <- "8"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1733"] <- "8"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1734"] <- "6"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1736"] <- "2"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1738"] <- "1"
nodups$CP_AgeYears[nodups$KI_Known_ID == "BHS_1739"] <- "4"
as.integer(nodups$CP_AgeYears)


library(tidyverse)
renodups <- distinct(nodups)
table(duplicated(renodups))
table(duplicated(renodups$DateObsTimeIDwaterspecific))
# Before Age Years, 177 duplicates.
# Down to 80 duplicates after Age Years fixed.
# Now down to 54 duplicates.
# No more duplicates! Yay!
# View(duplicated(renodups$DateObsTimeIDwaterspecific))

```
Then, just to be sure, I cut the visitation data to the time periods when all cameras were running. This data should have already been cut, but I know that Ashley was not super meticulous in only going through the photos in the time period when all of the cameras in the range were running, so I feel like this is a good check.

At this time, I also checked that the GO_WaterSource and GO_RangeCode made sense for each range. I changed two entries that were actually Nopah but mistakenly CMPR.





``` {r}

as.character(renodups$GO_Date, renodups$GO_Time_HHMM)
renodups$DateTime <- paste(renodups$GO_Date, renodups$GO_Time_HHMM, sep = " ")
library(lubridate)
renodups$DateTime <- strptime(renodups$DateTime, "%Y%m%d %H:%M")
renodups$DateTimect <- as.POSIXct(renodups$DateTime, tz = "America/Los_Angeles", format = "%Y%m%d %H:%M")

# Making the GO_Date into a Date:
renodups$GO_Date <- strptime(renodups$GO_Date, "%Y%m%d")
renodups$GO_Date <- as.POSIXct(renodups$GO_Date, tz = "America/Los_Angeles", format = "%Y%m%d")

Marbobs <- renodups[renodups$GO_RangeCode == "Marb", ]
Marbcutobs <- Marbobs[(Marbobs$DateTimect >= as.POSIXct("2019-05-17 10:49:00") & Marbobs$DateTimect <= as.POSIXct("2019-05-24 23:59:59")) | (Marbobs$DateTimect >= as.POSIXct("2019-06-04 20:00:00") & Marbobs$DateTimect <= as.POSIXct("2019-06-12 13:32:00")) | (Marbobs$DateTimect >= as.POSIXct("2019-06-18 17:19:00") & Marbobs$DateTimect <= as.POSIXct("2019-06-22 23:59:59"))| (Marbobs$DateTimect >= as.POSIXct("2019-06-25 14:49:00") & Marbobs$DateTimect <= as.POSIXct("2019-06-30 10:46:00"))| (Marbobs$DateTimect >= as.POSIXct("2019-07-10 08:45:00") & Marbobs$DateTimect <= as.POSIXct("2019-07-13 23:00:18")) | (Marbobs$DateTimect >= as.POSIXct("2019-07-17 11:46:00") & Marbobs$DateTimect <= as.POSIXct("2019-07-25 10:30:00")) | (Marbobs$DateTimect >= as.POSIXct("2019-07-31 20:52:00") & Marbobs$DateTimect <= as.POSIXct("2019-08-04 13:13:03")) | (Marbobs$DateTimect >= as.POSIXct("2019-08-06 12:03:00") & Marbobs$DateTimect <= as.POSIXct("2019-08-10 12:03:23")), ]

BrsSobs <- renodups[renodups$GO_RangeCode == "BrsS", ]
BrsScutobs <- BrsSobs[(BrsSobs$DateTimect >= as.POSIXct("2019-06-04 15:04:00") & BrsSobs$DateTimect <= as.POSIXct("2019-06-16 08:27:00")) | (BrsSobs$DateTimect >= as.POSIXct("2019-06-18 17:36:00") & BrsSobs$DateTimect <= as.POSIXct("2019-06-25 16:25:00")) | (BrsSobs$DateTimect >= as.POSIXct("2019-06-25 17:05:00") & BrsSobs$DateTimect <= as.POSIXct("2019-07-29 10:36:00")) | (BrsSobs$DateTimect >= as.POSIXct("2019-08-01 14:32:00") & BrsSobs$DateTimect <= as.POSIXct("2019-08-12 11:13:00")),]

# I found a couple of entries that need to be fixed.
as.character(renodups$GO_RangeCode)
renodups$GO_RangeCode[renodups$DateObsTimeIDwaterspecific == "20190718BHS_174112:46NopaNA"] <- "Nopa"
renodups$GO_RangeCode[renodups$DateObsTimeIDwaterspecific == "20190722BHS_17405:26NopaNA"] <- "Nopa"
as.factor(renodups$GO_RangeCode)

cmprobs <- renodups[renodups$GO_RangeCode == "CMPR", ]
# Limiting the visitations to those in the mine area due to the lack of coverage of the southern stream thing. This is the same thing as removing 1731 and 1732 from the dataset.
cmprobs1 <- cmprobs[cmprobs$GO_WaterSource != "Piue", ]
cmprcutobs <-  cmprobs1[(cmprobs1$DateTimect >= as.POSIXct("2019-05-23 15:48:00") & cmprobs1$DateTimect <= as.POSIXct("2019-05-31 11:18:00")) | (cmprobs1$DateTimect >= as.POSIXct("2019-06-20 17:47:00") & cmprobs1$DateTimect <= as.POSIXct("2019-06-27 02:09:00")) | (cmprobs1$DateTimect >= as.POSIXct("2019-07-11 18:25:00") & cmprobs1$DateTimect <= as.POSIXct("2019-07-14 18:28:00")) | (cmprobs1$DateTimect >= as.POSIXct("2019-07-30 14:30:00") & cmprobs1$DateTimect <= as.POSIXct("2019-08-03 16:46:00")) | (cmprobs1$DateTimect >= as.POSIXct("2019-08-05 19:10:00") & cmprobs1$DateTimect <= as.POSIXct("2019-08-15 07:27:00")),]

nopaobs <- renodups[renodups$GO_RangeCode == "Nopa", ]
nopacutobs <- nopaobs[(nopaobs$DateTimect >= as.POSIXct("2019-06-06 09:18:00") & nopaobs$DateTimect <= as.POSIXct("2019-06-13 11:04:00")) | (nopaobs$DateTimect >= as.POSIXct("2019-06-25 09:00:00") & nopaobs$DateTimect <= as.POSIXct("2019-07-08 12:35:00")) | (nopaobs$DateTimect >= as.POSIXct("2019-07-16 19:03:00") & nopaobs$DateTimect <= as.POSIXct("2019-07-29 15:06:00")) | (nopaobs$DateTimect >= as.POSIXct("2019-07-29 19:55:00") & nopaobs$DateTimect <= as.POSIXct("2019-08-07 14:49:00")),]

allcut <- rbind(Marbcutobs, BrsScutobs, cmprcutobs, nopacutobs)
# write.xlsx(allcut, file = "allcutVisitationData122719.xlsx")
```
I then created figures of the number of individual sheep coming into water by day. When examining the data, I noticed that the days at the beginning and end of each period when all of the cameras were running had a lower number of sheep coming in than the rest of the days. This is easily attributable to the cameras being up and running for only part of these days. As such, I cut out these days from my dataset (which probably decreased by dataset by about ~20%). For the Marbles, I did leave in one day when the cameras were only not running between 11 pm and 12 am. I figured that this is acceptable given the extreme bias of sheep for diurnality, which was confirmed when going through the camera photos. I will need to limit other analyses to these time periods given the incomplete data on the start/end days.


```{r}
# Number of Individual Sheep Coming into Water by Day

marballsheepvisitsday <- as.data.frame(table(Marbcutobs$KI_Known_ID, Marbcutobs$GO_Date))
View(marballsheepvisitsday)
marballsheepvisitsday$Freq[marballsheepvisitsday$Freq == 2] <- 1
marballsheepvisitsday$Freq[marballsheepvisitsday$Freq == 3] <- 1
marballsheepvisitsday$Freq[marballsheepvisitsday$Freq == 4] <- 1
marballsheepvisitsday$Freq[marballsheepvisitsday$Freq == 5] <- 1
marbindsheepvisitperday <- as.data.frame(tapply(marballsheepvisitsday$Freq, list(marballsheepvisitsday$Var2), sum))
View(marbindsheepvisitperday)
marbindsheepvisitperday <- cbind(rownames(marbindsheepvisitperday), data.frame(marbindsheepvisitperday, row.names = NULL))
marbindsheepvisitperday$datenum <- as.character(marbindsheepvisitperday$`rownames(marbindsheepvisitperday)`)
marbindsheepvisitperday$datenum <- as.Date(marbindsheepvisitperday$`rownames(marbindsheepvisitperday)`, format = "%Y-%m-%d")
marbindsheepvisitperday$datenum <- as.numeric(marbindsheepvisitperday$datenum)

#Cutting the rows where the day wasn't complete. Inputting NA rows for uncovered days.
marbindsheepvisitperday <- marbindsheepvisitperday[(marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-06-12") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-06-18") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-06-30") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-07-10") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-07-17") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-07-25") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-08-04") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-08-06") & (marbindsheepvisitperday$`rownames(marbindsheepvisitperday)` != "2019-08-10"), ]

marbdatena <- read.csv("TotalSheepVisitationPerDayMarbNAs122919.csv", header = TRUE, sep = ",")
marbdatena$tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2...[marbdatena$tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2... == "#N/A"] <- NA
names(marbdatena)[names(marbdatena) == "rownames.marbindsheepvisitperday."] <- "rownames(marbindsheepvisitperday)"
marbdatena$datenum <- as.Date(marbdatena$datenum, format = "%Y-%m-%d")
marbdatena$datenum <- as.numeric(marbdatena$datenum)
marbindsheepvisitperday1 <- rbind(marbindsheepvisitperday, marbdatena)
marbindsheepvisitperday1$tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2... <- as.integer(marbindsheepvisitperday1$tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2...)
marbindsheepvisitperday1$`rownames(marbindsheepvisitperday)` <- as.Date(marbindsheepvisitperday1$`rownames(marbindsheepvisitperday)`, "%Y-%m-%d")

#Barplot can't get NA spaces
# barplot(tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2... ~ `rownames(marbindsheepvisitperday)`, data = marbindsheepvisitperday1, main = "Marbles Number of Individual Sheep Coming to Water by Day", xlab = "Date", ylab = "Number of Individual Sheep")
# xlim = c(0, 85), width = 1

# GGPLOT WORKS!
library(ggplot2)
ggplot(data = marbindsheepvisitperday1, aes(x = `rownames(marbindsheepvisitperday)`, y = tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2...)) +
  geom_bar(stat="identity") + scale_x_date(limits = as.Date(c("2019-05-17", "2019-08-10"))) + ggtitle("Marbles Number of Individual Sheep Coming to Water by Day") + xlab("Date") + ylab("Number of Individual Sheep")



# df.expanded <- df[rep(row.names(df), df$freq), 1:2]
```

```{r}
# Mean Number of Visits Per Day for all sheep (and Standard Deviations)
 
# I deleted the start and end days that weren't fully covered.
Marbcutobsrd <- Marbcutobs[(Marbcutobs$GO_Date != "2019-06-12") & (Marbcutobs$GO_Date != "2019-06-18") & (Marbcutobs$GO_Date != "2019-06-30") & (Marbcutobs$GO_Date != "2019-07-10") & (Marbcutobs$GO_Date != "2019-07-17") & (Marbcutobs$GO_Date != "2019-07-25") & (Marbcutobs$GO_Date != "2019-08-04") & (Marbcutobs$GO_Date != "2019-08-06") & (Marbcutobs$GO_Date != "2019-08-10"), ]

# In order to calculate the number of visits that each sheep had to water on a given day, I duplicated the rows with multiple visits in a single observation. If an observation had three visits in it, I duplicated the row 3x. 

# The Marbles had no observations with multiple visits once cut to the appropriate dates.

marballrd <- as.data.frame(table(Marbcutobsrd$KI_Known_ID, Marbcutobsrd$GO_Date))
marbindrd <- as.data.frame(tapply(marballrd$Freq, list(marballrd$Var2), mean))
marbindrd$sd <- tapply(marballrd$Freq, list(marballrd$Var2), sd)
marbindrd <- cbind(rownames(marbindrd), data.frame(marbindrd, row.names = NULL))

marbna2 <- read.csv("MarbNAv21120.csv", header = TRUE, sep = ",")
marbna2$tapply.marballrd.Freq..list.marballrd.Var2.mean[marbna2$tapply.marballrd.Freq..list.marballrd.Var2.mean == "#N/A"] <- NA
marbna2$sd.tapply.marballrd.Freq..list.marballrd.Var2...sd.[marbna2$sd.tapply.marballrd.Freq..list.marballrd.Var2...sd. == "#N/A"] <- NA
names(marbna2)[names(marbna2) == "rownames.marbindrd."] <- "rownames(marbindrd)"
names(marbna2)[names(marbna2) == "tapply.marballrd.Freq..list.marballrd.Var2.mean"] <- "tapply.marballrd.Freq..list.marballrd.Var2...mean."
names(marbna2)[names(marbna2) == "sd.tapply.marballrd.Freq..list.marballrd.Var2...sd."] <- "sd"
marbindrd11 <- rbind(marbindrd, marbna2)
marbindrd11$tapply.marballrd.Freq..list.marballrd.Var2...mean. <- as.numeric(marbindrd11$tapply.marballrd.Freq..list.marballrd.Var2...mean.)
marbindrd11$sd <- as.numeric(marbindrd11$sd)
marbindrd11$`rownames(marbindrd)` <- as.Date(marbindrd11$`rownames(marbindrd)` , "%Y-%m-%d")
library(ggplot2)



library(ggplot2)
ggplot(data = marbindsheepvisitperday1, aes(x = `rownames(marbindsheepvisitperday)`, y = tapply.marballsheepvisitsday.Freq..list.marballsheepvisitsday.Var2...)) +
  geom_bar(stat="identity") + scale_x_date(limits = as.Date(c("2019-05-17", "2019-08-10"))) + ggtitle("Marbles Number of Individual Sheep Coming to Water by Day") + xlab("Date") + ylab("Number of Individual Sheep")





# <- do.call("rbind", replicate(Marbcutobsrd[(Marbcutobsrd$KI_DG_FirstPhotoTime2)]))

# do.call("rbind", replicate(dataframe, number of time to duplicate, simplify = FALSE))
# df[rep(seq_lej(nrow(df)), each = 2), ]



```




```{r}
# NOPAH PLOT

NopahData <- read.csv("NopahBighornVisitsSummer2019csv.csv", header = TRUE, sep = ",")
View(NopahData)
str(NopahData)
library(tidyverse)
library(lubridate)
NopahData$DateAttempt <- ymd(NopahData$GO_Date)
# Need to calculate number of visitations/day. 
visitationsbyday <- as.data.frame(table(NopahData$KI_Known_ID, NopahData$DateAttempt))
View(visitationsbyday)
str(visitationsbyday)
colnames(visitationsbyday)[colnames(visitationsbyday) == "Var1"] <- "sheep"
colnames(visitationsbyday)[colnames(visitationsbyday) == "Var2"] <- "date"
colnames(visitationsbyday)[colnames(visitationsbyday) == "Freq"] <- "visits"

test <- data.frame(date = rep(seq(from = as.Date("2019-06-06"), to = as.Date("2019-08-07"), "days"), 5), sheep = c(rep("BHS_1736", 63), rep("BHS_1737", 63), rep("BHS_1738", 63), rep("BHS_1739", 63), rep("BHS_1740", 63)))
View(test)
mergedvisit <- merge(test, visitationsbyday,by = c("sheep","date"), all = TRUE)
View(mergedvisit)
str(mergedvisit)
mergedvisit$datenum <- as.numeric(mergedvisit$date)
# for 6/6-6/13
mergedvisit$visits[is.na(mergedvisit$visits) == TRUE & (18053 <= mergedvisit$datenum & mergedvisit$datenum <= 18060)] <- 0
# For 6/25-7/8
mergedvisit$visits[is.na(mergedvisit$visits) == TRUE & (18072 <= mergedvisit$datenum & mergedvisit$datenum <= 18085)] <- 0
# For 7/19-8/7 **** NOte - 4 hour period on 7/29 when wasn't covered... shouldn't include 7/29?
mergedvisit$visits[is.na(mergedvisit$visits) == TRUE & (18096 <= mergedvisit$datenum & mergedvisit$datenum <= 18115)] <- 0

# Systematically jittering the results by sheep so can see them on the plot.

mergedvisit$jitter <- mergedvisit$visits
mergedvisit$jitter[mergedvisit$sheep == "BHS_1737"] <- (mergedvisit$jitter[mergedvisit$sheep == "BHS_1737"] + 0.05)
mergedvisit$jitter[mergedvisit$sheep == "BHS_1736"] <- (mergedvisit$jitter[mergedvisit$sheep == "BHS_1736"] + 0.1)
mergedvisit$jitter[mergedvisit$sheep == "BHS_1739"] <- (mergedvisit$jitter[mergedvisit$sheep == "BHS_1739"] - 0.05)
mergedvisit$jitter[mergedvisit$sheep == "BHS_1740"] <- (mergedvisit$jitter[mergedvisit$sheep == "BHS_1740"] - 0.1)

plot(jitter ~ date, data = mergedvisit, type = "p", col = mergedvisit$sheep, main = "Nopah", xlab = "Date", ylab = "Visitations of Surface Water per Day")
# NEEDS TO BE FIXED legend(x = "topleft", legend = levels(mergedvisit$sheep), col = mergedvisit$sheep, cex = 1)









# for(i in 2019-06-06:2019-08-07){if ((visitationsbyday$Freq != 1 OR 2) AND (visitationsbyday$Var1 == "BHS_1736" | "BHS_1737" | "BHS_1738" | "BHS_1739" | "BHS_1740") AND (visitationsbyday$Var2 == i)) {
#          visitationsbyday$Freq == 0}}
?merge
# visitationsbyday <- count(NopahData$KI_Known_ID ~ NopahData$DateAttempt)
# plot(KI_Known_ID ~ GO_Date, data = NopahData)
# as.data.frame(table(count(nrow( NopahData[NopahData$KI_Known_ID == ""]))))
# for

# Attempt a different way:
NopahData2 <- read.csv("NopahRearranged2.csv", header = TRUE, sep = ",")
View(NopahData2)
plot(Visitations ~ Date, data = NopahData2, type = "b")

```



```{r}
# CASTLE PIUTE PLOT

CMPRData <- read.csv("CMPRBighornVisitsSummer2019csv.csv", header = TRUE, sep = ",")
View(CMPRData)
str(CMPRData)
CMPRData$DateAttempt <- ymd(CMPRData$GO_Date)
CMPRvisitationsbyday <- as.data.frame(table(CMPRData$KI_Known_ID, CMPRData$DateAttempt))
View(CMPRvisitationsbyday)
str(CMPRvisitationsbyday)
colnames(CMPRvisitationsbyday)[colnames(CMPRvisitationsbyday) == "Var1"] <- "sheep"
colnames(CMPRvisitationsbyday)[colnames(CMPRvisitationsbyday) == "Var2"] <- "date"
colnames(CMPRvisitationsbyday)[colnames(CMPRvisitationsbyday) == "Freq"] <- "visits"
### test1 <- data.frame( date = rep(seq(from = as.Date("2019-05-23"), to = as.Date("2019-08-15"), "days"), ))

# NEED TO DECIDE WHAT I'M DOING ABOUT STUPID PIUTE MTNS - SHEEP GOING BETWEEN PIUTE GUZZLER & SOUTH CREEK THING!!!!!
```


This is an attempt to make it so I can do the real number of visits, accounting for the difference between the number of observations and the number of visits.

```{r}

# df.expanded <- df[rep(row.names(df), df$freq), 1:2]

```





```{r}
# SOUTH BRISTOLS PLOT

BrsSData <- read.csv("BrsSBighornVisitsSummer2019csv.csv", header = TRUE, sep = ",")
str(BrsSData)
View(BrsSData)
library(tidyverse)
library(lubridate)
BrsSData$DateAttempt <- ymd(BrsSData$GO_Date)
BrsSvisitationsbyday <- as.data.frame(table(BrsSData$KI_Known_ID, BrsSData$DateAttempt))
View(BrsSvisitationsbyday)
str(BrsSvisitationsbyday)
colnames(BrsSvisitationsbyday)[colnames(BrsSvisitationsbyday) == "Var1"] <- "sheep"
colnames(BrsSvisitationsbyday)[colnames(BrsSvisitationsbyday) == "Var2"] <- "date"
colnames(BrsSvisitationsbyday)[colnames(BrsSvisitationsbyday) == "Freq"] <- "visits"
test1 <- data.frame(date = rep(seq(from = as.Date("2019-06-04"), to = as.Date("2019-08-06"), "days"), 27), sheep = c(rep("BHS_1330", 64), rep("BHS_1340", 64), rep("BHS_1337", 64), rep("BHS_1334", 64), rep("BHS_1331", 64), rep("BHS_1329", 64), rep("BHS_1328", 64), rep("BHS_1333", 64), rep("BHS_1425", 64), rep("BHS_1426", 64), rep("BHS_1489", 64), rep("BHS_1491", 64), rep("BHS_1578", 64), rep("BHS_1579", 64), rep("BHS_1580", 64), rep("BHS_1596", 64), rep("BHS_1598", 64), rep("BHS_1599", 64), rep("BHS_1687", 64), rep("BHS_1486", 64), rep("BHS_1490", 64), rep("BHS_1492", 64), rep("BHS_1428", 64), rep("BHS_1685", 64), rep("BHS_1686", 64), rep("BHS_1688", 64), rep("BHS_1689", 64)))
View(test1)
BrsSmergedvisit <- merge(test1, BrsSvisitationsbyday, by = c("sheep", "date"), all = TRUE)
View(BrsSmergedvisit)
str(BrsSmergedvisit)
BrsSmergedvisit$datenum <- as.numeric(BrsSmergedvisit$date)
# for SBRS 6/4 - 6/16
BrsSmergedvisit$visits[is.na(BrsSmergedvisit$visits) == TRUE & (18051 <= BrsSmergedvisit$datenum & BrsSmergedvisit$datenum <= 	18063)] <- 0 
# for SBrs 6/18 - 7/29
BrsSmergedvisit$visits[is.na(BrsSmergedvisit$visits) == TRUE & (18065 <= BrsSmergedvisit$datenum & BrsSmergedvisit$datenum <= 	18106)] <- 0 
# for SBrs 8/1-8/6
BrsSmergedvisit$visits[is.na(BrsSmergedvisit$visits) == TRUE & (18109 <= BrsSmergedvisit$datenum & BrsSmergedvisit$datenum <= 		18114)] <- 0 
BrsSmergedvisit$jitter <- BrsSmergedvisit$visits
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1330"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1330"] + 0.02)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1340"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1340"] - 0.02)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1337"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1337"] + 0.04)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1334"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1334"] - 0.04)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1331"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1331"] + 0.06)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1329"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1329"] - 0.06)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1328"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1328"] + 0.08)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1333"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1333"] - 0.08)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1425"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1425"] + 0.10)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1426"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1426"] - 0.10)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1489"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1489"] + 0.12)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1580"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1580"] - 0.12)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1491"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1491"] + 0.14)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1596"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1596"] - 0.14)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1578"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1578"] + 0.16)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1579"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1579"] - 0.16)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1598"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1598"] + 0.18)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1599"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1599"] - 0.18)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1687"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1687"] + 0.20)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1486"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1486"] - 0.20)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1490"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1490"] + 0.22)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1492"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1492"] - 0.22)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1428"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1428"] + 0.24)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1685"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1685"] - 0.24)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1686"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1686"] + 0.26)
BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1688"] <- (BrsSmergedvisit$jitter[BrsSmergedvisit$sheep == "BHS_1688"] - 0.26)
plot(jitter ~ date, data = BrsSmergedvisit, type = "p", col = BrsSmergedvisit$sheep, main = "South Bristols", xlab = "Date", ylab = "Visitations to Surface Water per Day", cex = 0.75)


allgpsdata <- read.csv("AllGPSData20190501to20190912.csv", header = TRUE, sep = ",")


```


